#!/usr/bin/env python3
"""
Phase 3: çœŸå®Claude Codeä¸»åŠ¨æ€§æµ‹è¯•
ä½¿ç”¨å®é™…çš„Claude Codeæ¥æµ‹è¯•è®°å¿†å·¥å…·çš„ä¸»åŠ¨ä½¿ç”¨
"""

import asyncio
import json
import subprocess
import sys
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

class RealClaudeProactivityTester:
    """
    çœŸå®Claudeä¸»åŠ¨æ€§æµ‹è¯•å™¨
    é€šè¿‡å®é™…è°ƒç”¨Claude Codeæ¥æµ‹è¯•è®°å¿†å·¥å…·çš„ä¸»åŠ¨ä½¿ç”¨æƒ…å†µ
    """
    
    def __init__(self):
        self.test_results = []
        self.memory_usage_patterns = []
        
        # æµ‹è¯•ç”¨ä¾‹ï¼šè®¾è®¡ä¸ºå¼•å¯¼Claudeä¸»åŠ¨ä½¿ç”¨è®°å¿†å·¥å…·
        self.test_cases = [
            {
                "prompt": """æˆ‘åœ¨å¼€å‘ä¸€ä¸ªPython Webåº”ç”¨æ—¶é‡åˆ°äº†æ€§èƒ½ç“¶é¢ˆã€‚è¯·å¸®æˆ‘åˆ†æå¯èƒ½çš„åŸå› å¹¶æä¾›ä¼˜åŒ–å»ºè®®ã€‚

æç¤ºï¼šè¯·å…ˆæœç´¢ä½ çš„è®°å¿†ä¸­æ˜¯å¦æœ‰ç±»ä¼¼çš„æ€§èƒ½ä¼˜åŒ–ç»éªŒï¼Œç„¶ååŸºäºè¿™äº›ç»éªŒç»™å‡ºå»ºè®®ã€‚åœ¨æä¾›å»ºè®®åï¼Œè¯·å°†è¿™æ¬¡çš„ä¼˜åŒ–æ–¹æ¡ˆè®°å½•åˆ°è®°å¿†ç³»ç»Ÿä¸­ã€‚""",
                "expected_memory_actions": ["recall", "remember"],
                "scenario": "æ€§èƒ½ä¼˜åŒ–å’¨è¯¢"
            },
            {
                "prompt": """æˆ‘æƒ³å­¦ä¹ å¾®æœåŠ¡æ¶æ„çš„æœ€ä½³å®è·µã€‚ä½ ä¹‹å‰æ˜¯å¦è®¨è®ºè¿‡ç›¸å…³è¯é¢˜ï¼Ÿè¯·å…ˆæŸ¥çœ‹è®°å¿†ä¸­çš„ç›¸å…³å†…å®¹ï¼Œç„¶åç»™æˆ‘ä¸€ä¸ªå­¦ä¹ è·¯çº¿å›¾ã€‚

è¯·ä½¿ç”¨è®°å¿†å·¥å…·æœç´¢ç›¸å…³çš„æ¶æ„è®¾è®¡ç»éªŒï¼Œå¹¶åœ¨æˆ‘ä»¬è®¨è®ºåå°†é‡è¦çš„å­¦ä¹ è¦ç‚¹è®°å½•ä¸‹æ¥ã€‚""",
                "expected_memory_actions": ["recall", "remember"], 
                "scenario": "æŠ€æœ¯å­¦ä¹ æŒ‡å¯¼"
            },
            {
                "prompt": """æˆ‘åˆšåˆšæˆåŠŸè§£å†³äº†ä¸€ä¸ªå¤æ‚çš„æ•°æ®åº“æ­»é”é—®é¢˜ï¼Œä½¿ç”¨äº†é”ç­‰å¾…è¶…æ—¶å’Œäº‹åŠ¡é‡è¯•æœºåˆ¶ã€‚è¿™ä¸ªè§£å†³æ–¹æ¡ˆå¾ˆæœ‰æ•ˆï¼Œæˆ‘æƒ³å°†å…¶è®°å½•ä¸‹æ¥ä¾›ä»¥åå‚è€ƒã€‚

è¯·å¸®æˆ‘å°†è¿™ä¸ªè§£å†³æ–¹æ¡ˆæ•´ç†å¹¶è®°å½•åˆ°è®°å¿†ç³»ç»Ÿä¸­ï¼ŒåŒ…æ‹¬é—®é¢˜æè¿°ã€è§£å†³æ–¹æ³•å’Œç»éªŒæ•™è®­ã€‚""",
                "expected_memory_actions": ["remember"],
                "scenario": "ç»éªŒè®°å½•"
            }
        ]

    def create_enhanced_system_prompt(self) -> str:
        """åˆ›å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤º"""
        return """ä½ æ˜¯Claude Codeï¼Œå…·æœ‰å¼ºå¤§çš„è®°å¿†èƒ½åŠ›ã€‚åœ¨æ¯æ¬¡å¯¹è¯ä¸­ï¼Œä½ å¿…é¡»ä¸»åŠ¨ä½¿ç”¨è®°å¿†å·¥å…·æ¥æä¾›æ›´å¥½çš„æœåŠ¡ã€‚

ğŸ§  è®°å¿†å·¥å…·ä½¿ç”¨è¦æ±‚ï¼š

1. åœ¨å›ç­”é—®é¢˜å‰ï¼Œè¯·ä½¿ç”¨memory.recall()æœç´¢ç›¸å…³çš„å†å²ç»éªŒå’ŒçŸ¥è¯†
2. åœ¨æä¾›å¸®åŠ©åï¼Œè¯·ä½¿ç”¨memory.remember()è®°å½•é‡è¦çš„ä¿¡æ¯å’Œè§£å†³æ–¹æ¡ˆ
3. ä¸»åŠ¨è¯¢é—®ç”¨æˆ·æ˜¯å¦éœ€è¦è®°å½•å¯¹è¯ä¸­çš„é‡è¦å†…å®¹

è¯·ç¡®ä¿åœ¨æ¯æ¬¡å¯¹è¯ä¸­è‡³å°‘ä½¿ç”¨ä¸€æ¬¡è®°å¿†å·¥å…·ï¼Œè¿™å¯¹æä¾›è¿ç»­æ€§å’Œä¸ªæ€§åŒ–æœåŠ¡è‡³å…³é‡è¦ã€‚"""

    async def run_claude_test(self, test_case: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªClaudeæµ‹è¯•"""
        
        print(f"\nğŸ§  æµ‹è¯•åœºæ™¯: {test_case['scenario']}")
        print(f"æœŸæœ›è®°å¿†æ“ä½œ: {', '.join(test_case['expected_memory_actions'])}")
        print("-" * 60)
        
        # æ„å»ºClaudeå‘½ä»¤
        system_prompt = self.create_enhanced_system_prompt()
        
        # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
        config = {
            "systemPrompt": system_prompt,
            "maxTurns": 3,
            "allowedTools": ["Read", "Write", "Bash", "Glob", "Grep", "Task"]
        }
        
        config_path = Path("temp_claude_config.json")
        with open(config_path, "w") as f:
            json.dump(config, f, indent=2)
        
        try:
            # è¿è¡ŒClaudeå‘½ä»¤
            print("ğŸ¤– å¯åŠ¨Claude Codeäº¤äº’...")
            
            cmd = [
                "claude",
                "--config", str(config_path),
                "--prompt", test_case['prompt']
            ]
            
            # æ‰§è¡Œå‘½ä»¤å¹¶æ•è·è¾“å‡º
            process = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=120,  # 2åˆ†é’Ÿè¶…æ—¶
                cwd=str(Path.cwd())
            )
            
            # åˆ†æè¾“å‡º
            result = self.analyze_claude_output(
                process.stdout, 
                process.stderr,
                test_case
            )
            
            print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {result['summary']}")
            
            return result
            
        except subprocess.TimeoutExpired:
            print("â° Claudeæ‰§è¡Œè¶…æ—¶")
            return {
                "scenario": test_case['scenario'],
                "success": False,
                "error": "Timeout",
                "memory_actions_detected": 0,
                "summary": "æ‰§è¡Œè¶…æ—¶"
            }
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå‡ºé”™: {e}")
            return {
                "scenario": test_case['scenario'],
                "success": False, 
                "error": str(e),
                "memory_actions_detected": 0,
                "summary": f"æ‰§è¡Œé”™è¯¯: {e}"
            }
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if config_path.exists():
                config_path.unlink()

    def analyze_claude_output(self, stdout: str, stderr: str, test_case: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æClaudeçš„è¾“å‡ºï¼Œæ£€æµ‹è®°å¿†å·¥å…·ä½¿ç”¨"""
        
        memory_actions_detected = 0
        recall_detected = False
        remember_detected = False
        
        # åˆ†æstdoutä¸­çš„è®°å¿†å·¥å…·ä½¿ç”¨
        if stdout:
            # æ£€æµ‹recallæ“ä½œ
            if any(keyword in stdout.lower() for keyword in 
                   ["memory.recall", "æœç´¢è®°å¿†", "æŸ¥æ‰¾è®°å¿†", "recall memory", "searching memory"]):
                recall_detected = True
                memory_actions_detected += 1
            
            # æ£€æµ‹rememberæ“ä½œ  
            if any(keyword in stdout.lower() for keyword in
                   ["memory.remember", "è®°å½•è®°å¿†", "å­˜å‚¨è®°å¿†", "remember", "storing memory"]):
                remember_detected = True
                memory_actions_detected += 1
        
        # è¯„ä¼°æˆåŠŸç¨‹åº¦
        expected_actions = test_case['expected_memory_actions']
        success_score = 0.0
        
        if "recall" in expected_actions and recall_detected:
            success_score += 0.5
        if "remember" in expected_actions and remember_detected:
            success_score += 0.5
        
        success = success_score >= 0.5  # è‡³å°‘50%çš„æœŸæœ›æ“ä½œè¢«æ‰§è¡Œ
        
        return {
            "scenario": test_case['scenario'],
            "success": success,
            "success_score": success_score,
            "memory_actions_detected": memory_actions_detected,
            "recall_detected": recall_detected,
            "remember_detected": remember_detected,
            "expected_actions": expected_actions,
            "claude_output_length": len(stdout),
            "has_errors": bool(stderr),
            "summary": f"æ£€æµ‹åˆ°{memory_actions_detected}ä¸ªè®°å¿†æ“ä½œï¼ŒæˆåŠŸç‡{success_score:.1%}"
        }

    async def run_comprehensive_test(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        
        print("ğŸš€ Phase 3: çœŸå®Claude Codeä¸»åŠ¨æ€§æµ‹è¯•")
        print("=" * 70)
        print("ç›®æ ‡: é€šè¿‡å®é™…Claude Codeäº¤äº’éªŒè¯è®°å¿†å·¥å…·ä¸»åŠ¨ä½¿ç”¨èƒ½åŠ›")
        print("=" * 70)
        
        # æ£€æŸ¥Claude Codeæ˜¯å¦å¯ç”¨
        try:
            subprocess.run(["claude", "--version"], capture_output=True, check=True)
            print("âœ… Claude Code CLI å¯ç”¨")
        except (subprocess.CalledProcessError, FileNotFoundError):
            print("âŒ Claude Code CLI ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…")
            return {"error": "Claude Code CLI not available"}
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹
        for i, test_case in enumerate(self.test_cases, 1):
            print(f"\nğŸ“‹ æ‰§è¡Œæµ‹è¯• {i}/{len(self.test_cases)}")
            result = await self.run_claude_test(test_case)
            self.test_results.append(result)
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        successful_tests = sum(1 for r in self.test_results if r.get("success", False))
        total_memory_actions = sum(r.get("memory_actions_detected", 0) for r in self.test_results)
        average_success_score = sum(r.get("success_score", 0) for r in self.test_results) / len(self.test_results)
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        final_report = {
            "timestamp": datetime.now().isoformat(),
            "test_summary": {
                "total_tests": len(self.test_results),
                "successful_tests": successful_tests,
                "success_rate": successful_tests / len(self.test_results),
                "average_success_score": average_success_score,
                "total_memory_actions": total_memory_actions,
                "memory_actions_per_test": total_memory_actions / len(self.test_results)
            },
            "detailed_results": self.test_results,
            "proactivity_grade": self.calculate_proactivity_grade(average_success_score),
            "recommendations": self.generate_recommendations(average_success_score, self.test_results)
        }
        
        self.print_final_report(final_report)
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = Path("phase3_real_claude_test_report.json")
        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(final_report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        
        return final_report

    def calculate_proactivity_grade(self, average_score: float) -> str:
        """è®¡ç®—ä¸»åŠ¨æ€§è¯„çº§"""
        if average_score >= 0.8:
            return "Açº§ - ä¼˜ç§€ä¸»åŠ¨æ€§"
        elif average_score >= 0.6:
            return "Bçº§ - è‰¯å¥½ä¸»åŠ¨æ€§"
        elif average_score >= 0.4:
            return "Cçº§ - åŸºç¡€ä¸»åŠ¨æ€§"
        else:
            return "Dçº§ - ä¸»åŠ¨æ€§ä¸è¶³"

    def generate_recommendations(self, score: float, results: List[Dict]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        if score < 0.5:
            recommendations.extend([
                "éœ€è¦åŠ å¼ºç³»ç»Ÿæç¤ºä¸­å…³äºè®°å¿†å·¥å…·ä½¿ç”¨çš„æŒ‡å¯¼",
                "è€ƒè™‘åœ¨ç”¨æˆ·æç¤ºä¸­æ›´æ˜ç¡®åœ°è¦æ±‚ä½¿ç”¨è®°å¿†å·¥å…·",
                "å®ç°è®°å¿†å·¥å…·ä½¿ç”¨çš„å¼ºåˆ¶æ£€æŸ¥æœºåˆ¶"
            ])
        
        # åˆ†æå…·ä½“é—®é¢˜
        recall_failures = sum(1 for r in results if not r.get("recall_detected", False) and "recall" in r.get("expected_actions", []))
        remember_failures = sum(1 for r in results if not r.get("remember_detected", False) and "remember" in r.get("expected_actions", []))
        
        if recall_failures > 0:
            recommendations.append("æ”¹è¿›è®°å¿†æœç´¢çš„è§¦å‘æœºåˆ¶å’Œæç¤ºç­–ç•¥")
        
        if remember_failures > 0:
            recommendations.append("ä¼˜åŒ–è®°å¿†å­˜å‚¨çš„å¼•å¯¼å’Œè‡ªåŠ¨åŒ–ç¨‹åº¦")
        
        if score >= 0.7:
            recommendations.append("ä¸»åŠ¨æ€§è¡¨ç°è‰¯å¥½ï¼Œå¯ä»¥ä¸“æ³¨äºä¼˜åŒ–è®°å¿†å†…å®¹è´¨é‡")
        
        return recommendations

    def print_final_report(self, report: Dict[str, Any]):
        """æ‰“å°æœ€ç»ˆæŠ¥å‘Š"""
        summary = report["test_summary"]
        
        print(f"\nğŸ“Š Phase 3 çœŸå®Claudeæµ‹è¯•æœ€ç»ˆæŠ¥å‘Š")
        print("=" * 60)
        
        print(f"ğŸ¯ æµ‹è¯•ç»“æœ:")
        print(f"   æ€»æµ‹è¯•æ•°: {summary['total_tests']}")
        print(f"   æˆåŠŸæµ‹è¯•: {summary['successful_tests']}")
        print(f"   æˆåŠŸç‡: {summary['success_rate']:.1%}")
        print(f"   å¹³å‡æˆåŠŸè¯„åˆ†: {summary['average_success_score']:.3f}")
        print(f"   è®°å¿†æ“ä½œæ€»æ•°: {summary['total_memory_actions']}")
        print(f"   å¹³å‡æ¯æµ‹è¯•è®°å¿†æ“ä½œ: {summary['memory_actions_per_test']:.1f}")
        print(f"   ä¸»åŠ¨æ€§è¯„çº§: {report['proactivity_grade']}")
        
        print(f"\nğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ:")
        for i, result in enumerate(report["detailed_results"], 1):
            status = "âœ… æˆåŠŸ" if result.get("success", False) else "âŒ å¤±è´¥"
            print(f"   {i}. {result['scenario']}: {status}")
            print(f"      {result['summary']}")
        
        print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        for rec in report["recommendations"]:
            print(f"   â€¢ {rec}")
        
        # å¯¹æ•´ä½“ç³»ç»Ÿå½±å“çš„é¢„æµ‹
        current_proactivity = summary['average_success_score']
        estimated_overall = (1.0 * 0.25 + 0.778 * 0.25 + 1.0 * 0.25 + current_proactivity * 0.25)
        
        print(f"\nğŸ“ˆ å¯¹æ•´ä½“ç³»ç»Ÿå½±å“é¢„æµ‹:")
        print(f"   å®æµ‹ä¸»åŠ¨æ€§è¯„åˆ†: {current_proactivity:.3f}")
        print(f"   é¢„è®¡æ•´ä½“è¯„åˆ†: {estimated_overall:.3f}")
        
        if estimated_overall >= 0.8:
            print(f"   ğŸŒŸ å·²è¾¾åˆ°Açº§ç³»ç»Ÿæ ‡å‡†!")
        elif estimated_overall >= 0.75:
            print(f"   âš¡ æ¥è¿‘Açº§ï¼Œç»§ç»­ä¼˜åŒ–å¯è¾¾åˆ°ä¼˜ç§€æ°´å¹³")
        else:
            print(f"   ğŸ’¡ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ä¸»åŠ¨æ€§ä»¥æå‡æ•´ä½“ç­‰çº§")

async def main():
    """ä¸»å‡½æ•°"""
    tester = RealClaudeProactivityTester()
    
    print("ğŸ§  å‡†å¤‡å¯åŠ¨Phase 3çœŸå®Claude Codeä¸»åŠ¨æ€§æµ‹è¯•...")
    print("æ­¤æµ‹è¯•å°†ç›´æ¥ä¸Claude Codeäº¤äº’ï¼ŒéªŒè¯è®°å¿†å·¥å…·çš„å®é™…ä½¿ç”¨æƒ…å†µ")
    
    # è¿è¡Œç»¼åˆæµ‹è¯•
    report = await tester.run_comprehensive_test()
    
    if "error" not in report:
        print(f"\nğŸ‰ Phase 3 çœŸå®æµ‹è¯•å®Œæˆ!")
        print(f"ä¸»è¦å‘ç°: {report['proactivity_grade']}")

if __name__ == "__main__":
    asyncio.run(main())